# SPF
Official Implementation for "Subcellular particle fingerprints and behavior model enables for highly precise temporal super-resolved live-cell imaging"


## Dependencies and Installation
1. Clone Repo

   ```bash
   git clone https://github.com/sduzzx857/SPF-VFI.git
   ```

2. Create Conda Environment and Install Dependencies

   ```bash
   conda env create -f environment.yaml
   conda activate spf
   ```
## Pretrained Models

You can download the pretrained SPF model from [Google Driver](https://drive.google.com/drive/folders/1v3XXAmuJZOov1JaOiWMNhmJvKj8iM_Ee?usp=sharing)

The model path should be as follows:

```
GMSF2D/pretrained/
    MICROTUBULE7high750_64_4.pth
    MICROTUBULE7low85_64_4.pth
    RECEPTOR7high910_64_4.pth
    RECEPTOR7low110_64_4.pth
    VESICLE7high1100_64_4.pth
    VESICLE7low135_64_4.pth
pretrained/
    AMT/syn.pth
    CCR5.pth
    EB1.pth
    LYSOSOME.pth
    MICROTUBULE-high.pth
    MICROTUBULE-low.pth
    RECEPTOR-high.pth
    RECEPTOR-low.pth
    VESICLE-high.pth
    VESICLE-low.pth
```
* The `./GMSF2D/pretrained/` folder contains the pretrained model for the behavior model based on GMSF. 
* The `./pretrained/AMT/` folder contains the pretrained model for the frame synthesis module based on AMT. 
* The `./pretrained/` folder contains the pretrained model for the SPF-based interpolation model.

## Quick Demo

We have provided sample image sequences in the `./demos/images/` folder, along with the `.xml` files generated by tracking the particles in the image sequences using the Trackmate plugin.

1. Run `extract_particle.py` to extract particle coordinates from the ``.xml`` file and save them in the ``./demos/particle_loc/`` folder.

```bash
python demos/extract_particle.py
```

2. Run `demo_2x.py` to double the temporal resolution of the sample image sequence and save the results in the ``./demos/results/`` folder.

 ```bash
 python demos/demo_2x.py
 ```

## Download Datasets
Please download preprocessed datasets from [the zenodo repository](https://zenodo.org/records/14043236). Or you can download the datasets from the original paper or repository and preprocess the dataset according to the following literatures:

* The simulated testing datasets can be downloaded from [the 2014 ISBI Particle Tracking Challenge](http://bioimageanalysis.org/track/). 
* The EB1 datasets can be downloaded from the paper [The dynamic behavior of the APC-binding protein EB1 on the distal ends of microtubules](https://www.cell.com/current-biology/fulltext/S0960-9822(00)00600-X?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS096098220000600X%3Fshowall%3Dtrue).  We used *Movie2* from the Supplementary data. Please name the video as `video.mov`, place it in the `./data_process/EB1/` folder, and run the following command to generate the training and testing datasets:

  ```bash
  python data_process/EB1/mov.py
  python data_process/EB1/resize.py
  ```

* The CCR5 datasets can be downloaded from the paper [Tracking receptor motions at the plasma membrane reveals distinct effects of ligands on CCR5 dynamics depending on its dimerization status](https://elifesciences.org/articles/76281). We used *Video4* in the Results section. Please name the video as `video.mp4`, place it in the `./data_process/CCR5/` folder, and run the following command to generate the training and testing datasets:

  ```bash
  python data_process/CCR5/mp4.py
  python data_process/CCR5/resize.py
  ```
* The Lysosome datasets can be downloaded from [Content-Aware Frame Interpolation Microscopy Datasets](https://zenodo.org/records/10076346). We used data from the `Zproject` folder within the compressed file `Source_Data_Lysosomes_z-proj_Fig_5.zip`, containing a total of 39 images. The first 20 images are used as the training set, while the remaining 19 images serve as the testing set.



The downloaded data path should be as follows:

```
data_root/
    SIMULATED/
        test/
            MICROTUBULE/
                MICROTUBULE snr 7 density low/
                MICROTUBULE snr 7 density high/
            RECEPTOR/
                RECEPTOR snr 7 density low/
                RECEPTOR snr 7 density high/
            VESICLE/
                VESICLE snr 7 density low/
                VESICLE snr 7 density high/
        train/
            MICROTUBULE/
            RECEPTOR/
            VESICLE/
    REAL/
        CCR5/
            test/
            train/
        EB1/
            test/
            train/
        LYSOSOME/
            test/
            train/
```

## Dataset Preprocess

1. 生成基于GMSF的行为模型的测试集与训练集, 注意需要将--root修改为你自己的保存数据的路径:

    ```bash
    python GMSF2D/extract_particle.py --root data/
    ```

2. 生成基于SPF的插帧模型的测试集与训练集的粒子坐标部分，, 注意需要将--root修改为你自己的保存数据的路径:

    ```bash
    python data_process/extract_particle.py --root data/
    ```


## Evaluation

1. 测试基于GMSF的行为模型, 注意需要将test.sh中的--root修改为你自己的保存数据的路径

    ```shell
    ./GMSF2D/test.sh
    ```

2. 测试基于SPF的插帧模型, 注意需要将--root修改为你自己的保存数据的路径

    ```shell
    python benchmarks/Particle.py --root data/
    ```

## Training

1. Run the following commands for training 基于GMSF的行为模型:
    ```shell
    ./GMSF2D/train.sh [CKP] [DATA] [DEN] [NPT] [STEP]
    ## e.g.
    ./GMSF2D/train.sh GMSF2D/checkpoints/MICROTUBULE-low MICROTUBULE low 85 20000
    ```

2. 修改cfgs/文件夹下.yaml config文件中的data_root为你自己保存数据的路径
3. Before training, please first prepare the optical flows (which are used for supervision).

    We need to install `cupy` first before flow generation:

    ```shell
    conda activate spf # satisfying `requirement.txt`
    conda install -c conda-forge cupy
    ```

    After installing `cupy`, we can generate optical flows by the following command:  

    ```shell
    ./flow_generation/gen_flow_particle.sh
    ```
4. After obtaining the optical flow of the training data, run the following commands for training:

    ```shell
    ./train.sh [PORT] [CFG]
    ## e.g.
    ./train.sh 14514 cfgs/CCR5.yaml
    ```


